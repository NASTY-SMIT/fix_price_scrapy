# Асинхронный парсер товаров Fix-price

# В проекте реализовано:
- Сбор данных о товарах из разных категорий (Уход за полостью рта, Настольные игры, Красота и здоровье для тела) по определенному шаблону (один товар - один словарь):
```
{
    "timestamp": int,  # Дата и время сбора товара в формате timestamp.
    "RPC": "str",  # Уникальный код товара.
    "url": "str",  # Ссылка на страницу товара.
    "title": "str",  # Заголовок/название товара.
    "marketing_tags": ["str"],  # Список маркетинговых тэгов.
    "brand": "str",  # Бренд товара.
    "section": ["str"],  # Иерархия разделов, например: ['Игрушки', 'Развивающие и интерактивные игрушки', 'Интерактивные игрушки'].
    "price_data": {
        "current": float,  # Цена со скидкой, если скидки нет то = original.
        "original": float,  # Оригинальная цена.
        "sale_tag": "str"  # Если есть скидка на товар то запись формате: "Скидка {discount_percentage}%".
    },
    "assets": {
        "main_image": "str",  # Ссылка на основное изображение товара.
        "set_images": ["str"],  # Список ссылок на все изображения товара.
        "view_zoom": ["str"],  # Список ссылок на изображения в формате zoom.
    },
    "metadata": {
        "__description": "str",  # Описание товара
        "KEY": "str",
        "KEY": "str",
        "KEY": "str"
        # KEY - наименование характеристики, которая генерируется автоматически для каждого товара
    }
}
```
- Все данные выгружаются в файл fix_price.json, при повторном запуске паука файл перезаписывается
- Осуществляется сбор данных с учетом выбранного региона для парсинга - Екатеринбург

## Описание:
- Проект написан по стандарту PEP8, использовался линтинг flake8.
- Есть возможность подключения через proxy, при условии собственного proxy-сервера
- Проект упакован в Docker

### Используемые технологии
- Python 3.10
- Scrapy 2.11.1

## Архитектура проекта

| Директория                 | Описание                                                |
|----------------------------|---------------------------------------------------------|
| `fix_price_scrapy`         | Код парсера                                             |
| `fix_price_scrapy/spiders` | Код паука, который парсит данные                        |

## Требования

1. **Python 3.10**  
   Убедитесь, что у вас установлена нужная версия Python или активирована в
   `pyenv`.

2. **Poetry**  
   Зависимости и пакеты управляются через poetry. Убедитесь, что poetry [установлен](https://python-poetry.org/docs/#installing-with-the-official-installer)
   на вашем компьютере и ознакомьтесь с [документацией](https://python-poetry.org/docs/basic-usage/).  
   Установка зависимостей из корневой дирректории проекта

   ```
   poetry install
   ```

   Также будет создано виртуальное окружение, если привычнее видеть его в
   директории проекта, то
   используйте [настройку](https://python-poetry.org/docs/configuration/#adding-or-updating-a-configuration-setting) `virtualenvs.in-project`

3. **Docker**
- [Документация](https://docs.docker.com/)
- [Установка docker на Linux](https://docs.docker.com/engine/install/ubuntu/)
- [Установка docker на Windows](https://docs.docker.com/desktop/install/windows-install/)

# Разворачиваем проект локально

1. Устанавливаем зависимости
  ```
   poetry install
   ```
2. Активируем виртуальное окружение
  ```
   poetry shell
   ```
3. Запускаем паука
  ```
   scrapy crawl fix_price
   ```
4. Ждем, пока паук отработает и команда закончит свое выполнение, открываем файл `fix_price.json` и смотрим результат

# Разворачиваем проект в контейнерах

Переходим в корневую директорию проекта

```shell
cd fix_price_scrapy
```

Поднимаем контейнеры
```shell
sudo docker-compose up --build
```
Ждем, пока паук отработает и команда закончит свое выполнение, открываем файл `fix_price.json` и смотрим результат

- Если вы хотите изменить категории для парсинга (можно изменить только категории, нельзя менять сайт!), перейдите в файл `fix_price_scrapy/settings.py` и замените ссылки из `START_URLS` на свои собственные.
- Если вы хотите подключаться к сайту через proxy:
  1. Перейдите в файл `fix_price_scrapy/spiders/fix_price.py`, раскоментируйте нужный код и замените <> на свои значения
  2. Аналогично перейдите в файл `fix_price_scrapy/middlewares.py`, раскоментируйте нужный код и замените <> на свои значения
  3. Перейдите в файл `fix_price_scrapy/settings.py`, раскоментируйте нужный код
- Если вы хотите видеть логи паука в консоли, уберите в `fix_price_scrapy/settings.py` строку `LOG_LEVEL = 'ERROR'`

❤️Автор [Nasty Shmidt](https://github.com/NASTY-SMIT)❤️
[Обратная связь](https://t.me/nastyShmidt) - Telegram